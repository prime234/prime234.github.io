

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.ico">
  <link rel="icon" href="/img/favicon.ico">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="emroy">
  <meta name="keywords" content="">
  
    <meta name="description" content="Hadoop基本操作Hadoop Shell基本操作 实验过程及代码： 打开终端模拟器，启动Hadoop开启相关DataNode、NameNode、SecondaryNameNode、Jps等相关进程。  123cd &#x2F;apps&#x2F;hadoop&#x2F;sbin        &#x2F;&#x2F;切换到&#x2F;apps&#x2F;hadoop&#x2F;sbin目录下.&#x2F;start-all.sh            &#x2F;&#x2F;启动Hadoopjps">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop基本操作">
<meta property="og:url" content="https://www.prime.org.cn/2021/03/09/Hadoop%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/index.html">
<meta property="og:site_name" content="EMROY&#39;S BLOG">
<meta property="og:description" content="Hadoop基本操作Hadoop Shell基本操作 实验过程及代码： 打开终端模拟器，启动Hadoop开启相关DataNode、NameNode、SecondaryNameNode、Jps等相关进程。  123cd &#x2F;apps&#x2F;hadoop&#x2F;sbin        &#x2F;&#x2F;切换到&#x2F;apps&#x2F;hadoop&#x2F;sbin目录下.&#x2F;start-all.sh            &#x2F;&#x2F;启动Hadoopjps">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/prime234/Picture-PicGo/images/had1.jpg">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/prime234/Picture-PicGo/images/had2.jpg">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/prime234/Picture-PicGo/images/had3.jpg">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/prime234/Picture-PicGo/images/had4.jpg">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/prime234/Picture-PicGo/images/had5.jpg">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/prime234/Picture-PicGo/images/had6.jpg">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/prime234/Picture-PicGo/images/mapreduce">
<meta property="article:published_time" content="2021-03-09T15:53:57.000Z">
<meta property="article:modified_time" content="2023-01-12T08:56:06.000Z">
<meta property="article:author" content="emroy">
<meta property="article:tag" content="Hadoop">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/prime234/Picture-PicGo/images/had1.jpg">
  
  
  
  <title>Hadoop基本操作 - EMROY&#39;S BLOG</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"www.prime.org.cn","root":"/","version":"1.9.7","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/totoro.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 4.2.1"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Emroy&#39;s Blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>Home</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>Archives</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>Categories</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>Tags</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>About</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Hadoop基本操作"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2021-03-09 23:53" pubdate>
          March 9, 2021 pm
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          6.2k words
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          52 mins
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">Hadoop基本操作</h1>
            
            
              <div class="markdown-body">
                
                <h3 id="Hadoop基本操作"><a href="#Hadoop基本操作" class="headerlink" title="Hadoop基本操作"></a>Hadoop基本操作</h3><h4 id="Hadoop-Shell基本操作"><a href="#Hadoop-Shell基本操作" class="headerlink" title="Hadoop Shell基本操作"></a>Hadoop Shell基本操作</h4><hr>
<h5 id="实验过程及代码："><a href="#实验过程及代码：" class="headerlink" title="实验过程及代码："></a>实验过程及代码：</h5><ol>
<li>打开终端模拟器，启动Hadoop开启相关DataNode、NameNode、SecondaryNameNode、Jps等相关进程。</li>
</ol>
<figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli"><span class="hljs-keyword">cd</span> <span class="hljs-string">/apps/hadoop/sbin</span>        <span class="hljs-string">//</span>切换到<span class="hljs-string">/apps/hadoop/sbin</span>目录下<br><span class="hljs-string">./start-all.sh</span>            <span class="hljs-string">//</span>启动Hadoop<br>jps              <span class="hljs-string">//</span>检查相关进程是否启动<br></code></pre></td></tr></table></figure>

<ol start="2">
<li>在Hadoop中创建、修改、查看、删除文件夹test1及文件data.txt。</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs bash">hadoop fs -<span class="hljs-built_in">mkdir</span> /test1               //在/目录下创建一个test1文件夹<br>hadoop fs -touchz /test1/file.txt     //在Hadoop中的test1文件夹中创建一个file.txt文件hadoop fs -<span class="hljs-built_in">ls</span> /             //查看根目录下所有文件<br>hadoop fs -<span class="hljs-built_in">ls</span> -R /          //使用<span class="hljs-built_in">ls</span> -R的方式递归查看根下所有文件<br>hadoop fs -<span class="hljs-built_in">mv</span> /test1/file.txt /file2.txt        //将Hadoop根下test1目录中的file.txt文件，移动到根下并重命名为file2.txt<br>hadoop fs -<span class="hljs-built_in">cp</span> /file2.txt /test1       //将Hadoop根下的file2.txt文件复制到test1目录下<br><span class="hljs-built_in">cd</span> /data         //切换Linux本地/data目录下<br><span class="hljs-built_in">touch</span> data.txt       //创建一个data.txt文件<br><span class="hljs-built_in">echo</span> hello hadoop! &gt;&gt; data.txt      //写入hello hadoop!<br>hadoop fs -put /data/data.txt /test1      //将Linux本地/data目录下的data.txt文件，上传到HDFS中的/test1目录下<br>hadoop fs -<span class="hljs-built_in">cat</span> /test1/data.txt       //查看Hadoop中/test1目录下的data.txt文件<br>hadoop fs -<span class="hljs-built_in">tail</span> /test1/data.txt         //使用<span class="hljs-built_in">tail</span>方法查看data.txt文件<br>hadoop fs -<span class="hljs-built_in">du</span> -s /test1/data.txt        //查看Hadoop中/test1目录下的data.txt文件大小<br>hadoop fs -text /test1/data.txt    //使用text方法将源文件输出为文本格式<br>hadoop fs -<span class="hljs-built_in">stat</span> /test1/data.txt    //stat方法返回指定路径的统计信息,不指定format时候打印文件创建日期，相当于%y。<br>hadoop fs -get /test1/data.txt /apps        //将Hadoop中/test1目录下的data.txt文件，下载到Linux本地/apps目录中<br><span class="hljs-built_in">ls</span> /apps                 //查看一下/apps目录下是否存在data.txt文件<br></code></pre></td></tr></table></figure>

<ol start="3">
<li>使用chown方法，改变Hadoop&#x2F;test1目录中的data.txt文件拥有者和权限。</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">hadoop fs -<span class="hljs-built_in">chown</span> root /test1/data.txt      //使用<span class="hljs-built_in">chown</span>方法，改变Hadoop中/test1目录中的data.txt文件拥有者为root，使用-R将使改变在目录结构下递归进行。<br>hadoop fs -<span class="hljs-built_in">chmod</span> 777 /test1/data.txt     //使用<span class="hljs-built_in">chmod</span>方法，赋予Hadoop中/test1目录中的data.txt文件777权限<br>hadoop fs -<span class="hljs-built_in">rm</span> /file2.txt       //删除Hadoop根下的file2.txt文件<br>hadoop fs -<span class="hljs-built_in">rm</span> -r /test1        //删除Hadoop根下的test1目录<br>hadoop fs -expunge         //使用expunge方法清空回收站。<br></code></pre></td></tr></table></figure>

<ol start="4">
<li>使用Shell命令执行Hadoop自带的WordCount类</li>
</ol>
<figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli"><span class="hljs-keyword">cd</span> <span class="hljs-string">/data</span>      <span class="hljs-string">//</span>切换到<span class="hljs-string">/data</span>目录下<br>vim data.txt    <span class="hljs-string">//</span>使用vim编辑一个data.txt文件<br>hadoop fs -put <span class="hljs-string">/data/data.txt</span> <span class="hljs-string">/in</span>   <span class="hljs-string">//</span>在HDFS的根下创建in目录，并将<span class="hljs-string">/data</span>下的data.txt文件上传到HDFS中的in目录<br>hadoop jar <span class="hljs-string">/apps/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.0.0.jar</span> wordcount <span class="hljs-string">/in</span> <span class="hljs-string">/out</span>   <span class="hljs-string">//</span>执行hadoop jar命令，在hadoop的<span class="hljs-string">/apps/hadoop/share/hadoop/mapreduce</span>路径下存在hadoop-mapreduce-examples-3.0.0.jar包，执行其中的worldcount类，数据来源为HDFS的<span class="hljs-string">/in</span>目录，数据输出到HDFS的<span class="hljs-string">/out</span>目录<br><br>hadoop fs -ls <span class="hljs-string">/out</span>  <span class="hljs-string">//</span>查看HDFS中的<span class="hljs-string">/out</span>目录<br>hadoop fs -cat <span class="hljs-string">/out/</span>*<br>Hadoop fs - get <span class="hljs-string">/out/part-r-00000.txt</span> <span class="hljs-string">/data</span>   <span class="hljs-string">//</span>将HDFS中<span class="hljs-string">/out</span>下生成的文件，下载到Linux本地<span class="hljs-string">/data</span>目录中 <br></code></pre></td></tr></table></figure>

<ol start="5">
<li>进入Hadoop安全模式并退出。</li>
</ol>
<figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli">hdfs dfsadmin -safemode enter    <span class="hljs-string">//</span>进入hadoop安全模式<br>hdfs dfsadmin -safemode leave    <span class="hljs-string">//</span>退出Hadoop安全模式<br><span class="hljs-keyword">cd</span> <span class="hljs-string">/apps/hadoop/sbin</span>        <span class="hljs-string">//</span>切换到<span class="hljs-string">/apps/hadoop/sbin</span>目录下<br><span class="hljs-string">./stop-all.sh</span>            <span class="hljs-string">//</span>关闭Hadoop<br></code></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/prime234/Picture-PicGo/images/had1.jpg" srcset="/img/totoro.gif" lazyload alt="img"> </p>
<h4 id="HDFS-JAVA-API"><a href="#HDFS-JAVA-API" class="headerlink" title="HDFS JAVA API"></a>HDFS JAVA API</h4><hr>
<h5 id="实验过程及代码：-1"><a href="#实验过程及代码：-1" class="headerlink" title="实验过程及代码："></a>实验过程及代码：</h5><ol>
<li>在终端模拟器启动Hadoop，创建hadoop4目录，下载依赖包并解压到hadoop4目录；</li>
</ol>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs awk">cd <span class="hljs-regexp">/apps/</span>hadoop<span class="hljs-regexp">/sbin        /</span><span class="hljs-regexp">/切换目录到/</span>apps<span class="hljs-regexp">/hadoop/</span>sbin下，<br><br>.<span class="hljs-regexp">/start-all.sh            /</span>/启动hadoop。<br><br>mkdir -p <span class="hljs-regexp">/data/</span>hadoop4       <span class="hljs-regexp">//</span>在Linux本地创建<span class="hljs-regexp">/data/</span>hadoop4目录。<br><br>cd <span class="hljs-regexp">/data/</span>hadoop4          <span class="hljs-regexp">//</span>切换到<span class="hljs-regexp">/data/</span>hadoop4目录<br><br>wget http:<span class="hljs-regexp">//</span><span class="hljs-number">59.64</span>.<span class="hljs-number">78.41</span>:<span class="hljs-number">60000</span><span class="hljs-regexp">/allfiles/</span>hadoop4/hadoop2lib.tar.gz  <br><br>tar zxvf hadoop2lib.tar.gz    <span class="hljs-regexp">//</span>用wget命令，从http:<span class="hljs-regexp">//</span><span class="hljs-number">59.64</span>.<span class="hljs-number">78.41</span>:<span class="hljs-number">60000</span><span class="hljs-regexp">/allfiles/</span>hadoop4/网址上下载依赖包hadoop2lib.tar.gz，并解压到当前目录。<br></code></pre></td></tr></table></figure>

<ol start="2">
<li><p>打开Eclipse,新键Java Project,名为hadoop4，新建包my.hdfs，创建目录hadoop4lib存放依赖包，把jar包拷贝并全选，右键点击BuildPath&#x3D;&gt;Add to Build Path选项加载jar包到项目。</p>
</li>
<li><p>新建类MakeDir，功能：在HDFS的根目录下，创建名为hdfstest的目录。代码如下：</p>
</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">package</span> my.hdfs;  <br><span class="hljs-keyword">import</span> java.io.IOException;  <br><span class="hljs-keyword">import</span> java.net.URI;  <br><span class="hljs-keyword">import</span> java.net.URISyntaxException;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.conf.Configuration;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.fs.FileSystem;  <span class="hljs-comment">//FileSystem是一个通用文件系统的抽象基类，可以被分布式文件系统继承 </span><br><span class="hljs-keyword">import</span> org.apache.hadoop.fs.Path;  <br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">MakeDir</span> &#123;  <br>  <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> IOException, URISyntaxException &#123; <br>    <span class="hljs-type">Configuration</span> <span class="hljs-variable">conf</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Configuration</span>();  <span class="hljs-comment">//创建一个Configuration对象时，其构造方法会默认加载工程项目下两个配置文件，分别是hdfs-site.xml以及core-site.xml，这两个文件中会有访问HDFS所需的参数值，主要是fs.defaultFS，指定了HDFS的地址</span><br>    <span class="hljs-type">String</span> <span class="hljs-variable">hdfsPath</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;hdfs://localhost:9000&quot;</span>;  <br>    <span class="hljs-type">FileSystem</span> <span class="hljs-variable">hdfs</span> <span class="hljs-operator">=</span> FileSystem.get(<span class="hljs-keyword">new</span> <span class="hljs-title class_">URI</span>(hdfsPath), conf); <br>    <span class="hljs-type">String</span> <span class="hljs-variable">newDir</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;/hdfstest&quot;</span>;  <br> <span class="hljs-comment">//声明变量newDir，设置路径</span><br>    <span class="hljs-type">boolean</span> <span class="hljs-variable">result</span> <span class="hljs-operator">=</span> hdfs.mkdirs(<span class="hljs-keyword">new</span> <span class="hljs-title class_">Path</span>(newDir));  <br>    <span class="hljs-keyword">if</span> (result) &#123;  <br>      System.out.println(<span class="hljs-string">&quot;Success!&quot;</span>);  <br>    &#125;<span class="hljs-keyword">else</span> &#123;  <br>      System.out.println(<span class="hljs-string">&quot;Failed!&quot;</span>);  <br>    &#125;  <br>  &#125;  <br>&#125;  <br></code></pre></td></tr></table></figure>

<p><code>hadoop fs -ls -R /    // //使用ls -R的方式递归查看根下所有文件</code></p>
<ol start="4">
<li>新建类TouchFile，功能：在HDFS的目录&#x2F;hdfstest下，创建名为touchfile的文件.</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">package</span> my.hdfs; <br><span class="hljs-keyword">import</span> java.io.IOException; <br><span class="hljs-keyword">import</span> java.net.URI; <br><span class="hljs-keyword">import</span> java.net.URISyntaxException; <br><span class="hljs-keyword">import</span> org.apache.hadoop.conf.Configuration; <br><span class="hljs-keyword">import</span> org.apache.hadoop.fs.FSDataOutputStream; <br><span class="hljs-keyword">import</span> org.apache.hadoop.fs.FileSystem; <br><span class="hljs-keyword">import</span> org.apache.hadoop.fs.Path; <br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">TouchFile</span> &#123; <br>  <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> IOException, URISyntaxException &#123; <br>    <span class="hljs-type">Configuration</span> <span class="hljs-variable">configuration</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Configuration</span>();  <span class="hljs-comment">//创建一个Configuration对象configuration,</span><br>    <span class="hljs-type">String</span> <span class="hljs-variable">hdfsPath</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;hdfs://localhost:9000&quot;</span>; <br>    <span class="hljs-type">FileSystem</span> <span class="hljs-variable">hdfs</span> <span class="hljs-operator">=</span> FileSystem.get(<span class="hljs-keyword">new</span> <span class="hljs-title class_">URI</span>(hdfsPath), configuration);   <span class="hljs-comment">//用文件系统FileSystem声明一个实例hdfs</span><br>    <span class="hljs-type">String</span> <span class="hljs-variable">filePath</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;/hdfstest/touchfile&quot;</span>; <span class="hljs-comment">//声明变量 filePath表示文件路径</span><br>    <span class="hljs-type">FSDataOutputStream</span> <span class="hljs-variable">create</span> <span class="hljs-operator">=</span> hdfs.create(<span class="hljs-keyword">new</span> <span class="hljs-title class_">Path</span>(filePath));   <span class="hljs-comment">//FSDataOutputStream实例FileSystem返回FSDataOutputStream实例用create(Path p)函数，创建一个空文件，然后可以向该文件顺序写入</span><br>    System.out.println(<span class="hljs-string">&quot;Finish!&quot;</span>); <br><br>  &#125; <br><br>&#125; <br></code></pre></td></tr></table></figure>

<p><code>hadoop fs -ls -R /    // //使用ls -R的方式递归查看根下所有文件</code></p>
<ol start="5">
<li>cd &#x2F;data&#x2F;hadoop4 在&#x2F;data&#x2F;hadoop4下</li>
</ol>
<p><code>vim sample_data   //使用vim打开sample_data文件，</code></p>
<p>使用vim编辑输入a，开启输入模式</p>
<p><code>hello world   //输入hello world</code> </p>
<ol start="6">
<li>创建类CopyFromLocalFile.class，功能：将本地linux操作系统上的文件&#x2F;data&#x2F;hadoop4&#x2F;sample_data，上传到HDFS文件系统的&#x2F;hdfstest目录下。代码如下：</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">package</span> my.hdfs;  <br><span class="hljs-keyword">import</span> java.io.IOException;  <br><span class="hljs-keyword">import</span> java.net.URI;  <br><span class="hljs-keyword">import</span> java.net.URISyntaxException;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.conf.Configuration;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.fs.FileSystem;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.fs.Path;  <br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">CopyToLocalFile</span> &#123;  <br>  <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> IOException, URISyntaxException &#123; <br>    <span class="hljs-type">Configuration</span> <span class="hljs-variable">conf</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Configuration</span>();  <span class="hljs-comment">//声明环境配置变量conf</span><br>    <span class="hljs-type">String</span> <span class="hljs-variable">hdfsPath</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;hdfs://localhost:9000&quot;</span>;  <span class="hljs-comment">//声明URL路径</span><br>    <span class="hljs-type">FileSystem</span> <span class="hljs-variable">hdfs</span> <span class="hljs-operator">=</span> FileSystem.get(<span class="hljs-keyword">new</span> <span class="hljs-title class_">URI</span>(hdfsPath), conf);  <br> <span class="hljs-comment">//用文件系统FileSystem声明一个实例hdfs</span><br>    <span class="hljs-type">String</span> <span class="hljs-variable">from_HDFS</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;/hdfstest/sample_data&quot;</span>;  <br>    <span class="hljs-type">String</span> <span class="hljs-variable">to_Linux</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;/data/hadoop4/copytolocal&quot;</span>;  <br> <span class="hljs-comment">//复制文件路径</span><br>    hdfs.copyToLocalFile(<span class="hljs-literal">false</span>, <span class="hljs-keyword">new</span> <span class="hljs-title class_">Path</span>(from_HDFS), <span class="hljs-keyword">new</span> <span class="hljs-title class_">Path</span>(to_Linux));  <br> <span class="hljs-comment">//copyToLocalFile()方法拷贝文件到本地</span><br>    System.out.println(<span class="hljs-string">&quot;Finish!&quot;</span>);  <br>  &#125;  <br>&#125;  <br></code></pre></td></tr></table></figure>

<figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli"><span class="hljs-keyword">cd</span> <span class="hljs-string">/data/hadoop4/copytolocal</span> <span class="hljs-string">//</span>切换路径<br><span class="hljs-keyword">ls</span>  <span class="hljs-string">//</span>查看<br></code></pre></td></tr></table></figure>

<ol start="7">
<li>新建类ListFiles，程序功能是列出HDFS文件系统&#x2F;hdfstest目录下，所有的文件，以及文件的权限、用户组、所属用户。</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">package</span> my.hdfs; <br><span class="hljs-keyword">import</span> java.io.IOException; <br><span class="hljs-keyword">import</span> java.net.URI; <br><span class="hljs-keyword">import</span> org.apache.hadoop.conf.Configuration; <br><span class="hljs-keyword">import</span> org.apache.hadoop.fs.FileStatus; <br><span class="hljs-keyword">import</span> org.apache.hadoop.fs.FileSystem; <br><span class="hljs-keyword">import</span> org.apache.hadoop.fs.Path; <br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">ListFiles</span> &#123; <br>  <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> IOException &#123; <br>    <span class="hljs-type">Configuration</span> <span class="hljs-variable">conf</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Configuration</span>(); <span class="hljs-comment">//声明环境变量配置</span><br>    <span class="hljs-type">String</span> <span class="hljs-variable">hdfspath</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;hdfs://localhost:9000/&quot;</span>; <span class="hljs-comment">//定义文件路径</span><br>    <span class="hljs-type">FileSystem</span> <span class="hljs-variable">hdfs</span> <span class="hljs-operator">=</span> FileSystem.get(URI.create(hdfspath), conf); <br>    <span class="hljs-type">String</span> <span class="hljs-variable">watchHDFS</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;/hdfstest&quot;</span>; <span class="hljs-comment">//查看文件的源路径</span><br>    FileStatus[] files = hdfs.listStatus(<span class="hljs-keyword">new</span> <span class="hljs-title class_">Path</span>(watchHDFS)); <br>    <span class="hljs-keyword">for</span> (FileStatus file : files) &#123; <br>      System.out.println(file.getPermission() + <span class="hljs-string">&quot; &quot;</span> + file.getOwner() <br>          \+ <span class="hljs-string">&quot; &quot;</span> + file.getGroup() + <span class="hljs-string">&quot; &quot;</span> + file.getPath()); <br>    &#125; <br>  &#125; <br>&#125; <br></code></pre></td></tr></table></figure>

<p>执行结果：</p>
<p><img src="https://cdn.jsdelivr.net/gh/prime234/Picture-PicGo/images/had2.jpg" srcset="/img/totoro.gif" lazyload alt="img"> </p>
<ol start="8">
<li>新建类IteratorListFiles，功能：列出HDFS文件系统&#x2F;根目录下，以及各级子目录下，所有文件以及文件的权限、用户组，所属用户。</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">package</span> my.hdfs; <br><br><span class="hljs-keyword">import</span> java.io.FileNotFoundException; <br><span class="hljs-keyword">import</span> java.io.IOException; <br><span class="hljs-keyword">import</span> java.net.URI; <br><span class="hljs-keyword">import</span> org.apache.hadoop.conf.Configuration; <br><span class="hljs-keyword">import</span> org.apache.hadoop.fs.FileStatus; <br><span class="hljs-keyword">import</span> org.apache.hadoop.fs.FileSystem; <br><span class="hljs-keyword">import</span> org.apache.hadoop.fs.Path; <br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">IteratorListFiles</span> &#123; <br>  <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> IOException &#123; <br>    <span class="hljs-type">Configuration</span> <span class="hljs-variable">conf</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Configuration</span>(); <span class="hljs-comment">//声明环境配置变量</span><br>    <span class="hljs-type">String</span> <span class="hljs-variable">hdfspath</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;hdfs://localhost:9000/&quot;</span>; <br>    <span class="hljs-type">FileSystem</span> <span class="hljs-variable">hdfs</span> <span class="hljs-operator">=</span> FileSystem.get(URI.create(hdfspath), conf); <br>    <span class="hljs-type">String</span> <span class="hljs-variable">watchHDFS</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;/&quot;</span>; <span class="hljs-comment">//根目录路径</span><br>    iteratorListFile(hdfs, <span class="hljs-keyword">new</span> <span class="hljs-title class_">Path</span>(watchHDFS)); <br>  &#125; <br><br>  <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">iteratorListFile</span><span class="hljs-params">(FileSystem hdfs, Path path)</span> <br>      <span class="hljs-keyword">throws</span> FileNotFoundException, IOException &#123; <br>    FileStatus[] files = hdfs.listStatus(path); <br>    <span class="hljs-keyword">for</span> (FileStatus file : files) &#123; <br>      <span class="hljs-keyword">if</span> (file.isDirectory()) &#123; <br>        System.out.println(file.getPermission() + <span class="hljs-string">&quot; &quot;</span> + file.getOwner() <br>            \+ <span class="hljs-string">&quot; &quot;</span> + file.getGroup() + <span class="hljs-string">&quot; &quot;</span> + file.getPath()); <br>        iteratorListFile(hdfs, file.getPath()); <br>      &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (file.isFile()) &#123; <br>        System.out.println(file.getPermission() + <span class="hljs-string">&quot; &quot;</span> + file.getOwner() <br>            \+ <span class="hljs-string">&quot; &quot;</span> + file.getGroup() + <span class="hljs-string">&quot; &quot;</span> + file.getPath()); <br>      &#125; <br>    &#125; <br>  &#125; <br>&#125; <br></code></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/prime234/Picture-PicGo/images/had3.jpg" srcset="/img/totoro.gif" lazyload alt="img"> </p>
<ol start="9">
<li>新建类LocateFile，功能：查看HDFS文件系统上，文件&#x2F;hdfstest&#x2F;sample_data的文件块信息。</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">package</span> my.hdfs;  <br><br><span class="hljs-keyword">import</span> java.io.IOException;  <br><span class="hljs-keyword">import</span> java.net.URI;  <br><span class="hljs-keyword">import</span> java.net.URISyntaxException;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.conf.Configuration;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.fs.BlockLocation;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.fs.FileStatus;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.fs.FileSystem;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.fs.Path;  <br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">LocateFile</span> &#123;  <br>  <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> IOException, URISyntaxException &#123; <br>    <span class="hljs-type">Configuration</span> <span class="hljs-variable">conf</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Configuration</span>();  <span class="hljs-comment">//声明环境配置变量conf</span><br>    <span class="hljs-type">String</span> <span class="hljs-variable">hdfsPath</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;hdfs://localhost:9000&quot;</span>;  <br>    <span class="hljs-type">FileSystem</span> <span class="hljs-variable">hdfs</span> <span class="hljs-operator">=</span> FileSystem.get(<span class="hljs-keyword">new</span> <span class="hljs-title class_">URI</span>(hdfsPath), conf);  <br>    <span class="hljs-comment">//用文件系统FileSystem声明一个实例,获取文件地址</span><br>    <span class="hljs-type">Path</span> <span class="hljs-variable">file</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Path</span>(<span class="hljs-string">&quot;/hdfstest/sample_data&quot;</span>);  <span class="hljs-comment">//用Path变量file表示要打开文件的路径。</span><br>    <span class="hljs-type">FileStatus</span> <span class="hljs-variable">fileStatus</span> <span class="hljs-operator">=</span> hdfs.getFileStatus(file);  <span class="hljs-comment">//查看hdfs数据信息FileStatus对象封装了文件的和目录的额元数据，包括文件长度、块大小、权限等信息</span><br>    BlockLocation[] location = hdfs.getFileBlockLocations(fileStatus, <span class="hljs-number">0</span>, fileStatus.getLen());  <span class="hljs-comment">////文件块信息</span><br>    <span class="hljs-keyword">for</span> (BlockLocation block : location) &#123;  <br>      String[] hosts = block.getHosts();  <br>      <span class="hljs-keyword">for</span> (String host : hosts) &#123;  <br>        System.out.println(<span class="hljs-string">&quot;block:&quot;</span> +block + <span class="hljs-string">&quot; host:&quot;</span>+ host);  <br>      &#125;  <br>    &#125;  <br>  &#125;  <br>&#125; <br></code></pre></td></tr></table></figure>

<ol start="10">
<li>新建类WriteFile，功能：在HDFS上，创建&#x2F;hdfstest&#x2F;writefile文件并在文件中写入内容“hello world hello data!”。</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">package</span> my.hdfs;  <br><br><span class="hljs-keyword">import</span> java.io.IOException;  <br><span class="hljs-keyword">import</span> java.net.URI;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.conf.Configuration;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.fs.FSDataOutputStream;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.fs.FileSystem;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.fs.Path;  <br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">WriteFile</span> &#123;  <br>  <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> IOException &#123;  <br>    <span class="hljs-type">Configuration</span> <span class="hljs-variable">conf</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Configuration</span>();  <br>  <span class="hljs-comment">//声明环境配置变量conf</span><br>    <span class="hljs-type">String</span> <span class="hljs-variable">hdfsPath</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;hdfs://localhost:9000&quot;</span>;  <br>    <span class="hljs-type">FileSystem</span> <span class="hljs-variable">hdfs</span> <span class="hljs-operator">=</span> FileSystem.get(URI.create(hdfsPath), conf);  <span class="hljs-comment">//创建文件路径</span><br>    <span class="hljs-type">String</span> <span class="hljs-variable">filePath</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;/hdfstest/writefile&quot;</span>;  <span class="hljs-comment">//声明文件路径</span><br>    <span class="hljs-type">FSDataOutputStream</span> <span class="hljs-variable">create</span> <span class="hljs-operator">=</span> hdfs.create(<span class="hljs-keyword">new</span> <span class="hljs-title class_">Path</span>(filePath)); <br> <span class="hljs-comment">//创建一个空文件，然后可以向该文件顺序写入, FileSystem中的create()方法返回的是一个输出流FSDataOutputStream对象create</span><br>    System.out.println(<span class="hljs-string">&quot;Step 1 Finish!&quot;</span>);  <br> <span class="hljs-comment">//打印Step 1 Finish!</span><br>    <span class="hljs-type">String</span> <span class="hljs-variable">sayHi</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;hello world hello data!&quot;</span>;  <br>    <span class="hljs-type">byte</span>[] buff = sayHi.getBytes();  <br>    create.write(buff, <span class="hljs-number">0</span>, buff.length);  <br>    create.close();  <br>    System.out.println(<span class="hljs-string">&quot;Step 2 Finish!&quot;</span>);  <br>  &#125;  <br>&#125;  <br></code></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">hadoop fs -<span class="hljs-built_in">ls</span> -R /hdfstest <br><br>hadoop fs -<span class="hljs-built_in">cat</span> /hdfstest/writefile <br></code></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/prime234/Picture-PicGo/images/had4.jpg" srcset="/img/totoro.gif" lazyload alt="img"> </p>
<ol start="11">
<li>在linux本地创建&#x2F;data&#x2F;hadoop4&#x2F;testmerge目录。</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mkdir</span> -p /data/hadoop4/testmerge //在linux本地创建/data/hadoop4/testmerge目录。<br><span class="hljs-built_in">touch</span> file1  //新建文件file1<br><span class="hljs-built_in">touch</span> file2  //新建文件file2<br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;hello file1&quot;</span> &gt; file1  //在file1输入hello file1<br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;hello file2&quot;</span> &gt; file2  //在file2输入hello file2<br></code></pre></td></tr></table></figure>

<ol start="12">
<li>新建类PutMerge，功能：将Linux本地文件夹&#x2F;data&#x2F;hadoop4&#x2F;testmerge&#x2F;下的所有文件，上传到HDFS上并合并成一个文件&#x2F;hdfstest&#x2F;mergefile。</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">package</span> my.hdfs; <br><span class="hljs-keyword">import</span> java.io.IOException; <br><span class="hljs-keyword">import</span> java.net.URI; <br><span class="hljs-keyword">import</span> java.net.URISyntaxException; <br><span class="hljs-keyword">import</span> org.apache.hadoop.conf.Configuration; <br><span class="hljs-keyword">import</span> org.apache.hadoop.fs.FSDataInputStream; <br><span class="hljs-keyword">import</span> org.apache.hadoop.fs.FSDataOutputStream; <br><span class="hljs-keyword">import</span> org.apache.hadoop.fs.FileStatus; <br><span class="hljs-keyword">import</span> org.apache.hadoop.fs.FileSystem; <br><span class="hljs-keyword">import</span> org.apache.hadoop.fs.Path; <br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">PutMerge</span> &#123; <br>  <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> IOException, URISyntaxException &#123; <br>    <span class="hljs-type">Configuration</span> <span class="hljs-variable">conf</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Configuration</span>(); <span class="hljs-comment">//声明环境配置变量conf</span><br>    <span class="hljs-type">String</span> <span class="hljs-variable">hdfsPath</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;hdfs://localhost:9000&quot;</span>; <br>    <span class="hljs-type">FileSystem</span> <span class="hljs-variable">hdfs</span> <span class="hljs-operator">=</span> FileSystem.get(<span class="hljs-keyword">new</span> <span class="hljs-title class_">URI</span>(hdfsPath), conf); <br>    <span class="hljs-type">FileSystem</span> <span class="hljs-variable">local</span> <span class="hljs-operator">=</span> FileSystem.getLocal(conf); <br>    <span class="hljs-type">String</span> <span class="hljs-variable">from_LinuxDir</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;/data/hadoop4/testmerge/&quot;</span>; <br>    <span class="hljs-type">String</span> <span class="hljs-variable">to_HDFS</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;/hdfstest/mergefile&quot;</span>; <br>    FileStatus[] inputFiles = local.listStatus(<span class="hljs-keyword">new</span> <span class="hljs-title class_">Path</span>(from_LinuxDir)); <br>    <span class="hljs-type">FSDataOutputStream</span> <span class="hljs-variable">out</span> <span class="hljs-operator">=</span> hdfs.create(<span class="hljs-keyword">new</span> <span class="hljs-title class_">Path</span>(to_HDFS));   <span class="hljs-comment">//FileSystem中的create()方法返回的是一个输出流FSDataOutputStream对象out</span><br>    <span class="hljs-keyword">for</span> (FileStatus file : inputFiles) &#123; <br>      <span class="hljs-type">FSDataInputStream</span> <span class="hljs-variable">in</span> <span class="hljs-operator">=</span> local.open(file.getPath()); <span class="hljs-comment">//返回的是一个输入流FSDataInputStream对象</span><br>      <span class="hljs-type">byte</span>[] buffer = <span class="hljs-keyword">new</span> <span class="hljs-title class_">byte</span>[<span class="hljs-number">256</span>]; <span class="hljs-comment">//写入文件大小</span><br>      <span class="hljs-type">int</span> <span class="hljs-variable">bytesRead</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; <br>      <span class="hljs-keyword">while</span> ( (bytesRead = in.read(buffer) ) &gt; <span class="hljs-number">0</span>) &#123; <br>        out.write(buffer, <span class="hljs-number">0</span>, bytesRead); <br>      &#125; <br>      in.close(); <br>    &#125; <br>    System.out.println(<span class="hljs-string">&quot;Finish!&quot;</span>); <br>  &#125; <br>&#125; <br></code></pre></td></tr></table></figure>



<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">hadoop fs -<span class="hljs-built_in">ls</span> /hdfstest <br></code></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/prime234/Picture-PicGo/images/had5.jpg" srcset="/img/totoro.gif" lazyload alt="img"> </p>
<h4 id="开发YARN客户端应用"><a href="#开发YARN客户端应用" class="headerlink" title="开发YARN客户端应用"></a>开发YARN客户端应用</h4><hr>
<h5 id="实验过程及代码：-2"><a href="#实验过程及代码：-2" class="headerlink" title="实验过程及代码："></a>实验过程及代码：</h5><ol>
<li>启动hadoop,下载依赖包。</li>
</ol>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs awk">cd <span class="hljs-regexp">/apps/</span>hadoop<span class="hljs-regexp">/sbin      /</span><span class="hljs-regexp">/切换到/</span>apps<span class="hljs-regexp">/hadoop/</span>sbin目录下<br>.<span class="hljs-regexp">/start-all.sh           /</span>/启动hadoop<br>mkdir -p <span class="hljs-regexp">/data/y</span>arn       <span class="hljs-regexp">//</span>在Linux本地文件系统新建<span class="hljs-regexp">/data/y</span>arn目录。<br>cd <span class="hljs-regexp">/data/y</span>arn          <span class="hljs-regexp">//</span>切换到<span class="hljs-regexp">/data/y</span>arn目录下<br>wget http:<span class="hljs-regexp">//</span><span class="hljs-number">59.64</span>.<span class="hljs-number">78.41</span>:<span class="hljs-number">60000</span><span class="hljs-regexp">/allfiles/y</span>arn<span class="hljs-regexp">/hadoop2lib.tar.gz /</span><span class="hljs-regexp">/用wget命令从http:/</span><span class="hljs-regexp">/59.64.78.41:60000/</span>allfiles<span class="hljs-regexp">/yarn/</span>hadoop2lib.tar.gz网址上下载项目用到的依赖包。<br>tar zxvf hadoop2lib.tar.gz hadoop2lib 将hadoop2lib.tar.gz解压到当前目录下。<br></code></pre></td></tr></table></figure>

<ol start="2">
<li><p>添加项目所需的jar包。</p>
</li>
<li><p>打开Eclipse,新键Java Project,名为YARN，新建包my.yarn，创建目录lib存放依赖包，把jar包拷贝并全选，右键点击BuildPath&#x3D;&gt;Add to Build Path选项加载jar包到项目。</p>
</li>
<li><p>新建类，类名为Client。</p>
</li>
</ol>
<ul>
<li>客户端编写流程</li>
</ul>
<p>步骤1 Client通过RPC函数ClientRMProtocol.getNewApplication从ResourceManager中获取唯一的application ID</p>
<p>步骤2  Client通过RPC函数ClientRMProtocol#submitApplication将ApplicationMaster提交到ResourceManager上。</p>
<p>主要作用是提交(部署)应用和监控应用运行两个部分</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">package</span> my.yarn;  <br>  <br><span class="hljs-keyword">import</span> java.io.IOException;  <br><span class="hljs-keyword">import</span> java.util.HashMap;  <br><span class="hljs-keyword">import</span> java.util.LinkedList;  <br><span class="hljs-keyword">import</span> java.util.List;  <br><span class="hljs-keyword">import</span> java.util.Map;  <br><span class="hljs-keyword">import</span> org.apache.commons.io.FilenameUtils;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.conf.Configuration;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.fs.FileStatus;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.fs.FileSystem;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.fs.Path;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.security.UserGroupInformation;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.util.ClassUtil;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.yarn.api.ApplicationConstants;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.yarn.api.ApplicationConstants.Environment;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.yarn.api.records.ApplicationId;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.yarn.api.records.ApplicationReport;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.yarn.api.records.ContainerLaunchContext;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.yarn.api.records.LocalResource;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.yarn.api.records.LocalResourceType;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.yarn.api.records.LocalResourceVisibility;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.yarn.api.records.Priority;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.yarn.api.records.Resource;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.yarn.client.api.YarnClient;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.yarn.client.api.YarnClientApplication;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.yarn.conf.YarnConfiguration;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.yarn.exceptions.YarnException;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.yarn.util.ConverterUtils;  <br><span class="hljs-keyword">import</span> org.apache.log4j.Logger;  <br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Client</span> &#123;  <br>    <span class="hljs-keyword">static</span> <span class="hljs-keyword">private</span> <span class="hljs-type">Logger</span> <span class="hljs-variable">logger</span> <span class="hljs-operator">=</span> Logger.getLogger(<span class="hljs-string">&quot;Client.class&quot;</span>);  <br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception &#123;  <br>        <span class="hljs-type">Configuration</span> <span class="hljs-variable">conf</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Configuration</span>();  <br>        <span class="hljs-keyword">if</span> (UserGroupInformation.isSecurityEnabled()) &#123;  <br>            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Exception</span>(<span class="hljs-string">&quot;SecurityEnabled , not support&quot;</span>);  <br>        &#125;  <br>        <span class="hljs-comment">// 1. create and start a yarnClient  </span><br>        <span class="hljs-type">YarnClient</span> <span class="hljs-variable">yarnClient</span> <span class="hljs-operator">=</span> YarnClient.createYarnClient();  <br>        yarnClient.init(conf);  <br>        yarnClient.start();  <br>        <span class="hljs-comment">// 2. create an application  </span><br>        <span class="hljs-type">YarnClientApplication</span> <span class="hljs-variable">app</span> <span class="hljs-operator">=</span> yarnClient.createApplication();  <br>        ApplicationSubmissionContext appContext=app.getApplicationSubmissionContext();  <br>        ApplicationId appId=appContext.getApplicationId();  <br>        appContext.setApplicationName(<span class="hljs-string">&quot;my.yarn.ApplicationMaster&quot;</span>);  <br>        appContext.setKeepContainersAcrossApplicationAttempts(<span class="hljs-literal">false</span>);  <br>  <br>        <span class="hljs-comment">// 3. Set the app&#x27;s resource usage, 100*10MB, 1vCPU  </span><br>        <span class="hljs-type">Resource</span> <span class="hljs-variable">capability</span> <span class="hljs-operator">=</span> Resource.newInstance(<span class="hljs-number">100</span>, <span class="hljs-number">1</span>);  <br>        app.getApplicationSubmissionContext().setResource(capability);  <br>  <br>        <span class="hljs-comment">// 4. Set the app&#x27;s localResource env and command by  </span><br>        <span class="hljs-comment">// ContainerLaunchContext  </span><br>        <span class="hljs-type">ContainerLaunchContext</span> <span class="hljs-variable">amContainer</span> <span class="hljs-operator">=</span> createAMContainerLanunchContext(  <br>                conf, appId);  <br>        appContext.setAMContainerSpec(amContainer);  <br>        <span class="hljs-comment">// 5. submit to queue default  </span><br>        app.getApplicationSubmissionContext().setPriority(  <br>                Priority.newInstance(<span class="hljs-number">0</span>));  <br>        app.getApplicationSubmissionContext().setQueue(<span class="hljs-string">&quot;default&quot;</span>);  <br>        monitorApplicationReport(yarnClient, appId);  <br>    &#125;  <br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> ContainerLaunchContext <span class="hljs-title function_">createAMContainerLanunchContext</span><span class="hljs-params">(  </span><br><span class="hljs-params">            Configuration conf, ApplicationId appId)</span> <span class="hljs-keyword">throws</span> IOException &#123;  <br>  <br>        <span class="hljs-comment">//Add this jar file to hdfs  </span><br>        Map&lt;String, LocalResource&gt; localResources = <span class="hljs-keyword">new</span> <span class="hljs-title class_">HashMap</span>&lt;String, LocalResource&gt;();  <br>        <span class="hljs-type">FileSystem</span> <span class="hljs-variable">fs</span> <span class="hljs-operator">=</span> FileSystem.get(conf);  <br>        <span class="hljs-type">String</span> <span class="hljs-variable">thisJar</span> <span class="hljs-operator">=</span> ClassUtil.findContainingJar(Client.class);  <br>        <span class="hljs-type">String</span> <span class="hljs-variable">thisJarBaseName</span> <span class="hljs-operator">=</span> FilenameUtils.getName(thisJar);  <br>        logger.info(<span class="hljs-string">&quot;thisJar is &quot;</span> + thisJar);  <br>        System.out.println(<span class="hljs-string">&quot;thisJar is &quot;</span>+thisJar);  <br>        System.out.println(thisJarBaseName);  <br>        addToLocalResources(fs, thisJar, thisJarBaseName, appId.toString(),  <br>                localResources);  <br>        <span class="hljs-comment">//Set CLASSPATH environment  </span><br>        Map&lt;String, String&gt; env = <span class="hljs-keyword">new</span> <span class="hljs-title class_">HashMap</span>&lt;String, String&gt;();  <br>        <span class="hljs-type">StringBuilder</span> <span class="hljs-variable">classPathEnv</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">StringBuilder</span>(  <br>                Environment.CLASSPATH.$$());  <br>        classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);  <br>        classPathEnv.append(<span class="hljs-string">&quot;./*&quot;</span>);  <br>        <span class="hljs-keyword">for</span> (String c : conf  <br>                .getStrings(  <br>                        YarnConfiguration.YARN_APPLICATION_CLASSPATH,  <br>                        YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) &#123;  <br>            classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);  <br>            classPathEnv.append(c.trim());  <br>        &#125;  <br>        <span class="hljs-keyword">if</span> (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, <span class="hljs-literal">false</span>)) &#123;  <br>            classPathEnv.append(<span class="hljs-string">&#x27;:&#x27;</span>);  <br>            classPathEnv.append(System.getProperty(<span class="hljs-string">&quot;java.class.path&quot;</span>));  <br>        &#125;  <br>        env.put(Environment.CLASSPATH.name(), classPathEnv.toString());  <br>        <span class="hljs-comment">//Build the execute command  </span><br>        List&lt;String&gt; commands = <span class="hljs-keyword">new</span> <span class="hljs-title class_">LinkedList</span>&lt;String&gt;();  <br>    <span class="hljs-type">StringBuilder</span> <span class="hljs-variable">command</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">StringBuilder</span>();  <br>    command.append(Environment.JAVA_HOME.$$()).append(<span class="hljs-string">&quot;/bin/java  &quot;</span>);  <br>    command.append(<span class="hljs-string">&quot;-Dlog4j.configuration=container-log4j.properties &quot;</span>);  <br>    command.append(<span class="hljs-string">&quot;-Dyarn.app.container.log.dir=&quot;</span> +  <br>    ApplicationConstants.LOG_DIR_EXPANSION_VAR + <span class="hljs-string">&quot; &quot;</span>);  <br>    command.append(<span class="hljs-string">&quot;-Dyarn.app.container.log.filesize=0 &quot;</span>);  <br>    command.append(<span class="hljs-string">&quot;-Dhadoop.root.logger=INFO,CLA &quot;</span>);  <br>    command.append(<span class="hljs-string">&quot;my.yarn.ApplicationMaster&quot;</span>);  <br>    command.append(<span class="hljs-string">&quot;1&gt;&quot;</span> + ApplicationConstants.LOG_DIR_EXPANSION_VAR + <span class="hljs-string">&quot;/stdout &quot;</span>);  <br>    command.append(<span class="hljs-string">&quot;2&gt;&quot;</span> + ApplicationConstants.LOG_DIR_EXPANSION_VAR + <span class="hljs-string">&quot;/stderr &quot;</span>);  <br>    commands.add(command.toString());  <br>  <br>    <span class="hljs-type">ContainerLaunchContext</span> <span class="hljs-variable">amContainer</span> <span class="hljs-operator">=</span> ContainerLaunchContext  <br>    .newInstance(localResources, env, commands, <span class="hljs-literal">null</span>, <span class="hljs-literal">null</span>, <span class="hljs-literal">null</span>);  <br>    <span class="hljs-keyword">return</span> amContainer;  <br>    &#125;  <br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">addToLocalResources</span><span class="hljs-params">(FileSystem fs, String fileSrcPath,  </span><br><span class="hljs-params">    String fileDstPath, String appId,  </span><br><span class="hljs-params">    Map&lt;String, LocalResource&gt; localResources)</span>  <br>    <span class="hljs-keyword">throws</span> IllegalArgumentException, IOException &#123;  <br>    <span class="hljs-type">String</span> <span class="hljs-variable">suffix</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;data/YARN&quot;</span> + <span class="hljs-string">&quot;/&quot;</span> + appId + <span class="hljs-string">&quot;/&quot;</span> + fileDstPath;  <br>    System.out.println(fs.getHomeDirectory());  <br>    <span class="hljs-type">Path</span> <span class="hljs-variable">dst</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Path</span>(fs.getHomeDirectory(), suffix);  <br>    logger.info(<span class="hljs-string">&quot;hdfs copyFromLocalFile &quot;</span> + fileSrcPath + <span class="hljs-string">&quot; =&gt;&quot;</span> + dst);  <br>    fs.copyFromLocalFile(<span class="hljs-keyword">new</span> <span class="hljs-title class_">Path</span>(fileSrcPath), dst);  <br>    <span class="hljs-type">FileStatus</span> <span class="hljs-variable">scFileStatus</span> <span class="hljs-operator">=</span> fs.getFileStatus(dst);  <br>    <span class="hljs-type">LocalResource</span> <span class="hljs-variable">scRsrc</span> <span class="hljs-operator">=</span> LocalResource.newInstance(  <br>    ConverterUtils.getYarnUrlFromPath(dst), LocalResourceType.FILE,  <br>    LocalResourceVisibility.APPLICATION, scFileStatus.getLen(),  <br>    scFileStatus.getModificationTime());  <br>    localResources.put(fileDstPath, scRsrc);  <br>    &#125;  <br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">monitorApplicationReport</span><span class="hljs-params">(YarnClient yarnClient, ApplicationId appId)</span> <span class="hljs-keyword">throws</span> YarnException, IOException &#123;  <br>    <span class="hljs-keyword">while</span> (<span class="hljs-literal">true</span>) &#123;  <br>    <span class="hljs-keyword">try</span> &#123;  <br>    Thread.sleep(<span class="hljs-number">5</span> * <span class="hljs-number">1000</span>);  <br>    &#125; <span class="hljs-keyword">catch</span> (InterruptedException e) &#123;  <br>    &#125;  <br>    <span class="hljs-type">ApplicationReport</span> <span class="hljs-variable">report</span> <span class="hljs-operator">=</span> yarnClient.getApplicationReport(appId);  <br>    logger.info(<span class="hljs-string">&quot;Got application report &quot;</span> + <span class="hljs-string">&quot;, clientToAMToken=&quot;</span>  <br>    + report.getClientToAMToken() + <span class="hljs-string">&quot;, appDiagnostics=&quot;</span>  <br>    + report.getDiagnostics() + <span class="hljs-string">&quot;, appMasterHost=&quot;</span>  <br>    + report.getHost() + <span class="hljs-string">&quot;, appQueue=&quot;</span> + report.getQueue()  <br>    + <span class="hljs-string">&quot;, appMasterRpcPort=&quot;</span> + report.getRpcPort()  <br>    + <span class="hljs-string">&quot;, appStartTime=&quot;</span> + report.getStartTime()  <br>    + <span class="hljs-string">&quot;, yarnAppState=&quot;</span>  <br>    + report.getYarnApplicationState().toString()  <br>    + <span class="hljs-string">&quot;, distributedFinalState=&quot;</span>  <br>    + report.getFinalApplicationStatus().toString()  <br>    + <span class="hljs-string">&quot;, appTrackingUrl=&quot;</span> + report.getTrackingUrl()  <br>    + <span class="hljs-string">&quot;, appUser=&quot;</span> + report.getUser());  <br>    &#125;  <br>    &#125;  <br>    &#125;  <br></code></pre></td></tr></table></figure>

<ul>
<li>新建类，类名为ApplicationMaster。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br></pre></td><td class="code"><pre><code class="hljs java"><br><span class="hljs-keyword">package</span> my.yarn;  <br><span class="hljs-keyword">import</span> java.io.IOException;  <br><span class="hljs-keyword">import</span> java.nio.ByteBuffer;  <br><span class="hljs-keyword">import</span> java.util.LinkedList;  <br><span class="hljs-keyword">import</span> java.util.List;  <br><span class="hljs-keyword">import</span> java.util.Map;  <br><span class="hljs-keyword">import</span> java.util.concurrent.ConcurrentHashMap;  <br><span class="hljs-keyword">import</span> java.util.concurrent.ExecutorService;  <br><span class="hljs-keyword">import</span> java.util.concurrent.Executors;  <br><span class="hljs-keyword">import</span> java.util.concurrent.atomic.AtomicInteger;  <br><span class="hljs-keyword">import</span> org.apache.commons.logging.Log;  <br><span class="hljs-keyword">import</span> org.apache.commons.logging.LogFactory;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.conf.Configuration;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.net.NetUtils;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.yarn.api.ApplicationConstants;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.yarn.api.records.ApplicationAttemptId;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.yarn.api.records.Container;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.yarn.api.records.ContainerId;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.yarn.api.records.ContainerLaunchContext;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.yarn.api.records.ContainerStatus;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.yarn.api.records.FinalApplicationStatus;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.yarn.api.records.NodeReport;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.yarn.api.records.Priority;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.yarn.api.records.Resource;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.yarn.client.api.async.AMRMClientAsync;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.yarn.client.api.async.NMClientAsync;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.yarn.client.api.async.impl.NMClientAsyncImpl;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.yarn.exceptions.YarnException;  <br><span class="hljs-keyword">import</span> org.apache.hadoop.yarn.util.ConverterUtils;  <br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">ApplicationMaster</span> &#123;  <br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">AtomicInteger</span> <span class="hljs-variable">sleepSeconds</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">AtomicInteger</span>(<span class="hljs-number">0</span>);  <br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">LaunchContainerTask</span> <span class="hljs-keyword">implements</span> <span class="hljs-title class_">Runnable</span> &#123;  <br>        Container container;  <br>        <span class="hljs-keyword">public</span> <span class="hljs-title function_">LaunchContainerTask</span><span class="hljs-params">(Container container)</span> &#123;  <br>            <span class="hljs-built_in">this</span>.container = container;  <br>        &#125;  <br>        <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">run</span><span class="hljs-params">()</span> &#123;  <br>            List&lt;String&gt; commands = <span class="hljs-keyword">new</span> <span class="hljs-title class_">LinkedList</span>&lt;String&gt;();  <br>    commands.add(<span class="hljs-string">&quot;sleep &quot;</span> + sleepSeconds.addAndGet(<span class="hljs-number">1</span>));  <br>    <span class="hljs-type">ContainerLaunchContext</span> <span class="hljs-variable">ctx</span> <span class="hljs-operator">=</span> ContainerLaunchContext.newInstance(  <br>    <span class="hljs-literal">null</span>, <span class="hljs-literal">null</span>, commands, <span class="hljs-literal">null</span>, <span class="hljs-literal">null</span>, <span class="hljs-literal">null</span>);  <br>    amNMClient.startContainerAsync(container, ctx);  <br>    &#125;  <br>    &#125;  <br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">RMCallbackHandler</span> <span class="hljs-keyword">implements</span> <span class="hljs-title class_">AMRMClientAsync</span>.CallbackHandler &#123;  <br>  <br>  <br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">onContainersCompleted</span><span class="hljs-params">(List&lt;ContainerStatus&gt; statuses)</span> &#123;  <br>        <span class="hljs-keyword">for</span> (ContainerStatus status : statuses) &#123;  <br>        LOG.info(<span class="hljs-string">&quot;Container Completed: &quot;</span> + status.getContainerId().toString()  <br>        + <span class="hljs-string">&quot; exitStatus=&quot;</span>+ status.getExitStatus());  <br>        <span class="hljs-keyword">if</span> (status.getExitStatus() != <span class="hljs-number">0</span>) &#123;  <br>        <span class="hljs-comment">// restart  </span><br>        &#125;  <br>        <span class="hljs-type">ContainerId</span> <span class="hljs-variable">id</span> <span class="hljs-operator">=</span> status.getContainerId();  <br>        runningContainers.remove(id);  <br>        numCompletedConatiners.addAndGet(<span class="hljs-number">1</span>);  <br>        &#125;  <br>        &#125;  <br>        <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">onContainersAllocated</span><span class="hljs-params">(List&lt;Container&gt; containers)</span> &#123;  <br>            <span class="hljs-keyword">for</span> (Container c : containers) &#123;  <br>            LOG.info(<span class="hljs-string">&quot;Container Allocated&quot;</span>  <br>            + <span class="hljs-string">&quot;, id=&quot;</span> + c.getId()  <br>            + <span class="hljs-string">&quot;, containerNode=&quot;</span> + c.getNodeId());  <br>            exeService.submit(<span class="hljs-keyword">new</span> <span class="hljs-title class_">LaunchContainerTask</span>(c));  <br>            runningContainers.put(c.getId(), c);  <br>            &#125;  <br>            &#125;  <br>            <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">onShutdownRequest</span><span class="hljs-params">()</span> &#123;  <br>            &#125;  <br>            <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">onNodesUpdated</span><span class="hljs-params">(List&lt;NodeReport&gt; updatedNodes)</span> &#123;  <br>                &#125;  <br>                <span class="hljs-keyword">public</span> <span class="hljs-type">float</span> <span class="hljs-title function_">getProgress</span><span class="hljs-params">()</span> &#123;  <br>                <span class="hljs-type">float</span> <span class="hljs-variable">progress</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>;  <br>                <span class="hljs-keyword">return</span> progress;  <br>                &#125;  <br>                <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">onError</span><span class="hljs-params">(Throwable e)</span> &#123;  <br>                amRMClient.stop();  <br>                &#125;  <br>                &#125;  <br>                <span class="hljs-keyword">private</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">NMCallbackHandler</span> <span class="hljs-keyword">implements</span> <span class="hljs-title class_">NMClientAsync</span>.CallbackHandler &#123;  <br>                <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">onContainerStarted</span><span class="hljs-params">(ContainerId containerId,  </span><br><span class="hljs-params">                Map&lt;String, ByteBuffer&gt; allServiceResponse)</span> &#123;  <br>                LOG.info(<span class="hljs-string">&quot;Container Stared &quot;</span> + containerId.toString());  <br>                &#125;  <br>                <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">onContainerStatusReceived</span><span class="hljs-params">(ContainerId containerId,  </span><br><span class="hljs-params">                ContainerStatus containerStatus)</span> &#123;  <br>                &#125;  <br>                <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">onContainerStopped</span><span class="hljs-params">(ContainerId containerId)</span> &#123;  <br>                <span class="hljs-comment">// TODO Auto-generated method stub  </span><br>                &#125;  <br>                <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">onStartContainerError</span><span class="hljs-params">(ContainerId containerId, Throwable t)</span> &#123;  <br>                <span class="hljs-comment">// TODO Auto-generated method stub  </span><br>                &#125;  <br>                <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">onGetContainerStatusError</span><span class="hljs-params">(ContainerId containerId,  </span><br><span class="hljs-params">                Throwable t)</span> &#123;  <br>                <span class="hljs-comment">// TODO Auto-generated method stub  </span><br>                &#125;  <br>                <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">onStopContainerError</span><span class="hljs-params">(ContainerId containerId, Throwable t)</span> &#123;  <br>                <span class="hljs-comment">// TODO Auto-generated method stub  </span><br>                &#125;  <br>                &#125;  <br>  <br>                <span class="hljs-meta">@SuppressWarnings(&quot;rawtypes&quot;)</span>  <br>                <span class="hljs-type">AMRMClientAsync</span> <span class="hljs-variable">amRMClient</span> <span class="hljs-operator">=</span> <span class="hljs-literal">null</span>;  <br>                <span class="hljs-type">NMClientAsyncImpl</span> <span class="hljs-variable">amNMClient</span> <span class="hljs-operator">=</span> <span class="hljs-literal">null</span>;  <br>  <br>                <span class="hljs-type">AtomicInteger</span> <span class="hljs-variable">numTotalContainers</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">AtomicInteger</span>(<span class="hljs-number">10</span>);  <br>                <span class="hljs-type">AtomicInteger</span> <span class="hljs-variable">numCompletedConatiners</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">AtomicInteger</span>(<span class="hljs-number">0</span>);  <br>                <span class="hljs-type">ExecutorService</span> <span class="hljs-variable">exeService</span> <span class="hljs-operator">=</span> Executors.newCachedThreadPool();  <br>                Map&lt;ContainerId, Container&gt; runningContainers = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ConcurrentHashMap</span>&lt;ContainerId, Container&gt;();  <br>  <br>                <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">Log</span> <span class="hljs-variable">LOG</span> <span class="hljs-operator">=</span> LogFactory.getLog(ApplicationMaster.class);  <br>                <span class="hljs-meta">@SuppressWarnings(&quot;unchecked&quot;)</span>  <br>                <span class="hljs-keyword">void</span> <span class="hljs-title function_">run</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> YarnException, IOException &#123;  <br>                <span class="hljs-type">Configuration</span> <span class="hljs-variable">conf</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Configuration</span>();  <br>  <br>  <br>                <span class="hljs-comment">// 1. create amRMClient  </span><br>                amRMClient = AMRMClientAsync.createAMRMClientAsync(  <br>                <span class="hljs-number">1000</span>, <span class="hljs-keyword">new</span> <span class="hljs-title class_">RMCallbackHandler</span>());  <br>                amRMClient.init(conf);  <br>                amRMClient.start();  <br>  <br>                <span class="hljs-comment">// 2. Create nmClientAsync  </span><br>                amNMClient = <span class="hljs-keyword">new</span> <span class="hljs-title class_">NMClientAsyncImpl</span>(<span class="hljs-keyword">new</span> <span class="hljs-title class_">NMCallbackHandler</span>());  <br>                amNMClient.init(conf);  <br>                amNMClient.start();  <br>  <br>  <br>                <span class="hljs-comment">// 3. register with RM and this will heartbeating to RM  </span><br>                <span class="hljs-type">RegisterApplicationMasterResponse</span> <span class="hljs-variable">response</span> <span class="hljs-operator">=</span> amRMClient  <br>                .registerApplicationMaster(NetUtils.getHostname(), -<span class="hljs-number">1</span>, <span class="hljs-string">&quot;&quot;</span>);  <br>  <br>  <br>                <span class="hljs-comment">// 4. Request containers  </span><br>                response.getContainersFromPreviousAttempts();  <br>                <span class="hljs-type">int</span> <span class="hljs-variable">numContainers</span> <span class="hljs-operator">=</span> <span class="hljs-number">10</span>;  <br>                <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; numTotalContainers.get(); i++) &#123;  <br>                <span class="hljs-type">ContainerRequest</span> <span class="hljs-variable">containerAsk</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">ContainerRequest</span>(  <br>                <span class="hljs-comment">//100*10M + 1vcpu  </span><br>                Resource.newInstance(<span class="hljs-number">100</span>, <span class="hljs-number">1</span>), <span class="hljs-literal">null</span>, <span class="hljs-literal">null</span>,  <br>                Priority.newInstance(<span class="hljs-number">0</span>));  <br>                amRMClient.addContainerRequest(containerAsk);  <br>                &#125;  <br>                &#125;  <br>  <br>                <span class="hljs-keyword">void</span> <span class="hljs-title function_">waitComplete</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> YarnException, IOException&#123;  <br>                <span class="hljs-keyword">while</span>(numTotalContainers.get() != numCompletedConatiners.get())&#123;  <br>                <span class="hljs-keyword">try</span>&#123;  <br>                Thread.sleep(<span class="hljs-number">1000</span>);  <br>                LOG.info(<span class="hljs-string">&quot;waitComplete&quot;</span> +  <br>                <span class="hljs-string">&quot;, numTotalContainers=&quot;</span> + numTotalContainers.get() +  <br>                <span class="hljs-string">&quot;, numCompletedConatiners=&quot;</span> + numCompletedConatiners.get());  <br>                &#125; <span class="hljs-keyword">catch</span> (InterruptedException ex)&#123;&#125;  <br>                &#125;  <br>                LOG.info(<span class="hljs-string">&quot;ShutDown exeService Start&quot;</span>);  <br>                exeService.shutdown();  <br>                LOG.info(<span class="hljs-string">&quot;ShutDown exeService Complete&quot;</span>);  <br>                amNMClient.stop();  <br>                LOG.info(<span class="hljs-string">&quot;amNMClient  stop  Complete&quot;</span>);  <br>                amRMClient.unregisterApplicationMaster(FinalApplicationStatus.SUCCEEDED, <span class="hljs-string">&quot;dummy Message&quot;</span>, <span class="hljs-literal">null</span>);  <br>                LOG.info(<span class="hljs-string">&quot;unregisterApplicationMaster  Complete&quot;</span>);  <br>                amRMClient.stop();  <br>                LOG.info(<span class="hljs-string">&quot;amRMClient  stop Complete&quot;</span>);  <br>                &#125;  <br>                <span class="hljs-keyword">void</span> <span class="hljs-title function_">logInformation</span><span class="hljs-params">()</span> &#123;  <br>                System.out.println(<span class="hljs-string">&quot;This is System.out.println&quot;</span>);  <br>                System.err.println(<span class="hljs-string">&quot;This is System.err.println&quot;</span>);  <br>                <span class="hljs-type">String</span> <span class="hljs-variable">containerIdStr</span> <span class="hljs-operator">=</span> System  <br>                .getenv(ApplicationConstants.Environment.CONTAINER_ID.name());  <br>                LOG.info(<span class="hljs-string">&quot;containerIdStr &quot;</span> + containerIdStr);  <br>                <span class="hljs-type">ContainerId</span> <span class="hljs-variable">containerId</span> <span class="hljs-operator">=</span> ConverterUtils.toContainerId(containerIdStr);  <br>                <span class="hljs-type">ApplicationAttemptId</span> <span class="hljs-variable">appAttemptId</span> <span class="hljs-operator">=</span> containerId  <br>                .getApplicationAttemptId();  <br>                LOG.info(<span class="hljs-string">&quot;appAttemptId &quot;</span> + appAttemptId.toString());  <br>                &#125;  <br>                <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception &#123;  <br>                <span class="hljs-type">ApplicationMaster</span> <span class="hljs-variable">am</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">ApplicationMaster</span>();  <br>                am.run();  <br>                am.waitComplete();  <br>                &#125;  <br>                &#125;  <br></code></pre></td></tr></table></figure>

<ol start="5">
<li>代码编写完成后，将整个YARN项目打包成jar包，</li>
</ol>
<p>​     在Linux的命令行，切换到&#x2F;data&#x2F;yarn目录下</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> /data/yarn <br></code></pre></td></tr></table></figure>

<p>​     使用下面命令执行distributedshell。</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs stylus">hadoop org<span class="hljs-selector-class">.apache</span><span class="hljs-selector-class">.hadoop</span><span class="hljs-selector-class">.yarn</span><span class="hljs-selector-class">.applications</span><span class="hljs-selector-class">.distributedshell</span><span class="hljs-selector-class">.Client</span> \ <br><br>-jar hadoop-yarn-applications-distributedshell<span class="hljs-selector-class">.jar</span> \ <br><br>-num_containers <span class="hljs-number">10</span> \ <br><br>-shell_command ls \ <br><br>-priority <span class="hljs-number">10</span> <br></code></pre></td></tr></table></figure>

<p>执行结果：</p>
<img src="https://cdn.jsdelivr.net/gh/prime234/Picture-PicGo/images/had6.jpg" srcset="/img/totoro.gif" lazyload alt="img" style="zoom:80%;" />

<h4 id="相关知识总结"><a href="#相关知识总结" class="headerlink" title="相关知识总结"></a><em><strong>相关知识总结</strong></em></h4><ul>
<li><p>MapReduce介绍</p>
<p>MapReduce采用的是“分而治之”的思想，把对大规模数据集的操作，分发给一个主节点管理下的各个从节点共同完成，然后通过整合各个节点的中间结果，得到最终结果。简单来说，MapReduce就是”任务的分解与结果的汇总“。</p>
<ul>
<li>MapReduce的工作原理</li>
</ul>
<p>​          在分布式计算中，MapReduce框架负责处理了并行编程里分布式存储、工作调度，负载均衡、容错处理以及网络通信等复杂问题，现在我们把处理过程高度抽象为Map与Reduce两个部分来进行阐述，其中Map部分负责把任务分解成多个子任务，Reduce部分负责把分解后多个子任务的处理结果汇总起来，具体设计思路如下。</p>
<ol>
<li><p>Map过程需要继承org.apache.hadoop.mapreduce包中Mapper类，并重写其map方法。通过在map方法中添加两句把key值和value值输出到控制台的代码，可以发现map方法中输入的value值存储的是文本文件中的一行（以回车符为行结束标记），而输入的key值存储的是该行的首字母相对于文本文件的首地址的偏移量。然后用StringTokenizer类将每一行拆分成为一个个的字段，把截取出需要的字段（本实验为买家id字段）设置为key，并将其作为map方法的结果输出。</p>
</li>
<li><p>Reduce过程需要继承org.apache.hadoop.mapreduce包中Reducer类，并重写其reduce方法。Map过程输出的&lt;key,value&gt;键值对先经过shuffle过程把key值相同的所有value值聚集起来形成values，此时values是对应key字段的计数值所组成的列表，然后将&lt;key,values&gt;输入到reduce方法中，reduce方法只要遍历values并求和，即可得到某个单词的总次数。</p>
</li>
<li><p>在main()主函数中新建一个Job对象，由Job对象负责管理和运行MapReduce的一个计算任务，并通过Job的一些方法对任务的参数进行相关的设置。本实验是设置使用将继承Mapper的doMapper类完成Map过程中的处理和使用doReducer类完成Reduce过程中的处理。还设置了Map过程和Reduce过程的输出类型：key的类型为Text，value的类型为IntWritable。任务的输出和输入路径则由字符串指定，并由FileInputFormat和FileOutputFormat分别设定。完成相应任务的参数设定后，即可调用job.waitForCompletion()方法执行任务，其余的工作都交由MapReduce框架处理。</p>
<ul>
<li>MapReduce框架的作业运行流程</li>
</ul>
</li>
</ol>
<img src="https://cdn.jsdelivr.net/gh/prime234/Picture-PicGo/images/mapreduce" srcset="/img/totoro.gif" lazyload alt="img" style="zoom:80%;" />

<ul>
<li><p>ResourceManager：是YARN资源控制框架的中心模块，负责集群中所有资源的统一管理和分配。它接收来自NM(NodeManager)的汇报，建立AM，并将资源派送给AM(ApplicationMaster)。</p>
</li>
<li><p>NodeManager：简称NM，NodeManager是ResourceManager在每台机器上的代理，负责容器管理，并监控他们的资源使用情况（cpu、内存、磁盘及网络等），以及向ResourceManager提供这些资源使用报告。</p>
</li>
<li><p>ApplicationMaster：以下简称AM。YARN中每个应用都会启动一个AM，负责向RM申请资源，请求NM启动Container，并告诉Container做什么事情。</p>
</li>
<li><p>Container：资源容器。YARN中所有的应用都是在Container之上运行的。AM也是在Container上运行的，不过AM的Container是RM申请的。Container是YARN中资源的抽象，它封装了某个节点上一定量的资源（CPU和内存两类资源）。Container由ApplicationMaster向ResourceManager申请的，由ResouceManager中的资源调度器异步分配给ApplicationMaster。Container的运行是由ApplicationMaster向资源所在的NodeManager发起的，Container运行时需提供内部执行的任务命令（可以是任何命令，比如java、Python、C++进程启动命令均可）以及该命令执行所需的环境变量和外部资源（比如词典文件、可执行文件、jar包等）。</p>
</li>
</ul>
<p>另外，一个应用程序所需的Container分为两大类，如下：</p>
<ul>
<li>运行ApplicationMaster的Container：这是由ResourceManager（向内部的资源调度器）申请和启动的，用户提交应用程序时，可指定唯一的ApplicationMaster所需的资源。</li>
<li>运行各类任务的Container：这是由ApplicationMaster向ResourceManager申请的，并为了ApplicationMaster与NodeManager通信以启动的。</li>
</ul>
<p>以上两类Container可能在任意节点上，它们的位置通常而言是随机的，即ApplicationMaster可能与它管理的任务运行在一个节点上。</p>
<hr>
<ul>
<li>MapReduce将复杂的、运行于大规模集群上的并行计算过程高度地抽象到了两个函数：Map和Reduce</li>
<li>编程容易，不需要掌握分布式并行编程细节，也可以很容易把自己的程序运行在分布式系统上，完成海量数据的计算</li>
<li>MapReduce采用“分而治之”策略，一个存储在分布式文件系统中的大规模数据集，会被切分成许多独立的分片（split），这些分片可以被多个Map任务并行处理</li>
<li>MapReduce设计的一个理念就是“计算向数据靠拢”，而不是“数据向计算靠拢”，因为，移动数据需要大量的网络传输开销</li>
<li>MapReduce框架采用了Master&#x2F;Slave架构，包括一个Master和若干个Slave。Master上运行JobTracker，Slave上运行TaskTracker </li>
<li>Hadoop框架是用Java实现的，但是，MapReduce应用程序则不一定要用Java来写</li>
</ul>
</li>
<li><p>MapReduce优势</p>
</li>
</ul>
<table>
<thead>
<tr>
<th></th>
<th><strong>传统并行计算框架</strong></th>
<th><strong>MapReduce</strong></th>
</tr>
</thead>
<tbody><tr>
<td>集群架构&#x2F;容错性</td>
<td>共享式(共享内存&#x2F;共享存储)，容错性差</td>
<td>非共享式，容错性好</td>
</tr>
<tr>
<td>硬件&#x2F;价格&#x2F;扩展性</td>
<td>刀片服务器、高速网、SAN，价格贵，扩展性差</td>
<td>普通PC机，便宜，扩展性好</td>
</tr>
<tr>
<td>编程&#x2F;学习难度</td>
<td>what-how，难</td>
<td>what，简单</td>
</tr>
<tr>
<td>适用场景</td>
<td>实时、细粒度计算、计算密集型</td>
<td>批处理、非实时、数据密集型</td>
</tr>
</tbody></table>
<ul>
<li>Map函数和Reduce函数</li>
</ul>
<table>
<thead>
<tr>
<th><strong>函数</strong></th>
<th><strong>输入</strong></th>
<th align="left"><strong>输出</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td>Map</td>
<td>&lt;*k*1,v1&gt;如：&lt;行号,”a b c”&gt;</td>
<td align="left">List(&lt;*k*2,*v*2&gt;)如：&lt;“a”,1&gt;&lt;“b”,1&gt;&lt;“c”,1&gt;</td>
<td>1.将小数据集进一步解析成一批&lt;key,value&gt;对，输入Map函数中进行处理2.每一个输入的&lt;*k*1,*v*1&gt;会输出一批&lt;*k*2,*v*2&gt;。&lt;*k*2,*v*2&gt;是计算的中间结果</td>
</tr>
<tr>
<td>Reduce</td>
<td>&lt;*k*2,List(*v*2)&gt;如：&lt;“a”,&lt;1,1,1&gt;&gt;</td>
<td align="left">&lt;*k*3,*v*3&gt;&lt;“a”,3&gt;</td>
<td>输入的中间结果&lt;<em>k*2,List(<em>v</em>2)&gt;中的List(<em>v</em>2)表示是一批属于同一个</em>k*2的value</td>
</tr>
</tbody></table>
<ul>
<li><p>MapReduce体系结构主要由四个部分组成，分别是：Client、JobTracker、TaskTracker以及Task<br>    - Client<br>      用户编写的MapReduce程序通过Client提交到JobTracker端<br>用户可通过Client提供的一些接口查看作业运行状态</p>
<ul>
<li>JobTracker<br>   JobTracker负责资源监控和作业调度<br>   JobTracker 监控所有TaskTracker与Job的健康状况，一旦发现失败，就将相应的任务转移到其他节点<br>   JobTracker 会跟踪任务的执行进度、资源使用量等信息，并将这些信息告诉任务调度器（TaskScheduler），而调度器会在资源出现空闲时，选择合适的任务去使用这些资源</li>
<li>Client<br>   用户编写的MapReduce程序通过Client提交到JobTracker端<br>   用户可通过Client提供的一些接口查看作业运行状态</li>
<li>JobTracker<br>   JobTracker负责资源监控和作业调度<br>   JobTracker 监控所有TaskTracker与Job的健康状况，一旦发现失败，就将相应的任务转移到其他节点<br>   JobTracker 会跟踪任务的执行进度、资源使用量等信息，并将这些信息告诉任务调度器（TaskScheduler），而调度器会在资源出现空闲时，选择合适的任务去使用这些资源</li>
</ul>
</li>
<li><p>MapReduce工作流程</p>
<ol>
<li><p>不同的Map任务之间不会进行通信</p>
</li>
<li><p>不同的Reduce任务之间也不会发生任何信息交换</p>
</li>
<li><p>用户不能显式地从一台机器向另一台机器发送消息</p>
</li>
<li><p>所有的数据交换都是通过MapReduce框架自身去实现的</p>
</li>
<li><p>MapReduce执行的全过程包括以下几个主要阶段：</p>
<ul>
<li><p>从分布式文件系统读入数据</p>
</li>
<li><p>执行Map任务输出中间结果</p>
</li>
<li><p>通过 Shuffle阶段把中间结果分区排序整理后发送给Reduce任务</p>
</li>
<li><p>执行Reduce任务得到最终结果并写入分布式文件系统。</p>
</li>
</ul>
</li>
</ol>
<p>  MapReduce具有广泛的应用，比如关系代数运算、分组与聚合运算、矩阵-向量乘法、矩阵乘法等。</p>
<hr>
<p>Woooohhhhhh! Finally!!!</p>
</li>
</ul>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" class="category-chain-item">大数据</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/Hadoop/" class="print-no-link">#Hadoop</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Hadoop基本操作</div>
      <div>https://www.prime.org.cn/2021/03/09/Hadoop基本操作/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>Author</div>
          <div>emroy</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Posted on</div>
          <div>March 9, 2021</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>Licensed under</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - Attribution">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2021/03/26/JS6%E7%A7%8D%E7%BB%A7%E6%89%BF%E6%96%B9%E5%BC%8F/" title="JS6种继承方式">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">JS6种继承方式</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2021/01/01/%E5%BE%AE%E8%A7%822020/" title="微观2020🤗">
                        <span class="hidden-mobile">微观2020🤗</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>Table of Contents</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/wanko.model.json"},"display":{"position":"left","width":175,"height":200},"mobile":{"show":true},"log":false});</script></body>
</html>
